---
title: 项目设想——AI员工
date: 2024-05-05 16:50:55
tags: [企划]
topic: planning
type: story
indent: true
---

​	这个设想是很久之前就想过的，甚至尝试写过，但是那会没有一点编程能力，故放弃的非常快。现在重拾起来看看能不能尝试写出来，感觉这个东西写出来会对我未来的帮助很大，特别是知识和灵感汇总，项目进度管理之类的。

## 引言

​	在我看来，任何员工或者人做一类事情的过程无异于一个程序在执行一个算法，只不过算法的输入拥有极大的二义性，故传统算法无法处理自然语言输入。类似会计做财报，需要结合历史数据，专业知识和模板来进行操作做表，但是自然语言对这一事件的形容无非就是一句：“亲，麻烦你做一下我们公司xxxx年第x季度的财报”，传统算法肯定是无法识别这一点的。

​	但是在当下LLM模型蓬勃发展的时代就可以尝试去做到这一点，我们可以让LLM模型充当一个输入格式化工具，也可以让其作为一个数据库查找的引擎，我们只需要提供完整工作的处理逻辑和输出接口就可以了。

## 设想

{% image https://s21.ax1x.com/2024/05/05/pkAqGes.jpg %}

可以看出，我们其实要借ai来完成规范化的事物处理其实并不难进行开发

核心部件：

- 大模型
- 逻辑文档
- 数据库
- 事务处理接口

让我们明确一下这四个部分是怎样进行交互的：

### 大模型：

大模型有三个主要功能：

1. 与自然人生成交流语句
2. 根据逻辑文档对任务进行分类
3. 根据知识范围对资料进行查找和格式化

为了规范化用于，LLM到自然人和自然人到LLM的数据转换称为`自然人/标准转化`

### 逻辑文档：

​	由于当下的LLM模型是一个无完整逻辑能力的模型，我们不能够指望它一次思考能满足一整个任务的需要，所以我们需要逻辑文档来让LLM进行参考。

​	这个逻辑文档本质上就是一个我们人对整个事务流程的一个理解和认知——任务各个部分之间是怎么联系的、任务需要哪些知识来解决......——的一个文字型的抽象（前面也说了，LLM是没有逻辑能力的，所以逻辑文档虽然属于文字型的抽象，但是本质并不是让LLM去理解逻辑文档，而是通过代码硬编码逻辑顺序，让LLM根据我们所编排的顺序去执行事务）

​	可以理解为LLM并不能决定事务处理的过程，只能决定内容，而事务处理的过程由逻辑文档决定，也可以理解为逻辑文档是一个流程图。

### 数据库：

​	这个部分其实并不需要展开来讲，属于大模型部署和定制化的范畴，并不属于本文的探讨范围。数据库适用于储存员工领域的专业知识和逻辑文档（逻辑文档是逻辑抽象，并不是实际存在的，本质上就是LLM知识库中的一个层次）

### 事务处理接口

​	回想前言，我们提到过该框架中LLM并不负责事务的具体处理，而事务的具体处理则是需要调用某一类事物通用的事务处理接口进行处理（接口使用的数据类型的定义应该包含在输出结构文档中，接口使用的数据应该是由LLM进行格式化之后的）



### 设想总结

也就是其实本质上整个框架就是一个常规的自动化程序，不同点有三：

1. 输入输出要经过`自然人/标准转换`
2. 没有固定的查询范式，而是由LLM进行分类查询
3. 事务处理接口不单是进行某一种情景下的事物处理，而是通用的，面向一类相似情景的事物处理



## 猜想实现

### 逻辑文档的实现

​	我认为这个部分可以单独作为一种语言，{% u 无类型语言 %}，只用于形容标准的逻辑过程。逻辑过程可以说是面向保留字的，使用保留字对逻辑过程进行声明，而非保留字部分则视为对标准处理模块的调用。

```
input -> model with task-document -> model with knowledge -> model with "将这些知识按照格式化文档格式到json数据" with format-document -> make-table -> model with exchange-documents -> output
```

类似这样的感觉，保留字只有`""`、 `->` 和 `with` 

（这个代码是示范用例，实际上不会保留有`""`，因为代码是无类型的，而`with`会用合适的符号替代）

我想实现的是面向输入输出流编程，只编码输入输出的走向而不编码内容变化，内容交由库去处理。

另外就是逻辑文档的起点始终是一个`input`（这个是虚指的一个库，放置了触发此次逻辑的用户输入）

`model`——LLM的假定库，输入一个语料，输出生成内容

`with`——实际在流中指两段内容的字符串拼接

流的起点是一个函数的输出，终点是一个函数的输入，流内容传入时会自动调用对应的函数 

### 框架实现

​	大模型部署部分不在本文的范畴内，不做讨论，在这里大模型始终视为和数据库绑定的一个组件。框架实现猜想内部所有的编程思想和要素全部基于C#进行抽象。

​	我们首先猜想整个项目的结构层次树形图：

```c#
frame
|
│  main.exe
│
├─libs			// 这里存放框架运行的依赖
├─models
│  │  settings.yml   // 这里存放模型加载设置（什么模型需要加载，什么模型不需要加载，链接token等）
│  │
│  ├─model1        // 这里存放模型的部署（或者调用的sdk）
│  └─model2
└─staffs			// 这里是存放员工文件的目录
    └─demo-staff
        │  settings.yml			// 设置员工加载选项（lazy-load？) 和激活关键词
        │
        ├─documents			// 里面可以放置多个逻辑文档或单个（多个不推荐，因为让LLM自行决定有风险）
        └─utils				// 放置通用事务处理接口
```

​	大致结构如上，然后猜想运行流程如下：

​	用户`input`，然后内容传入框架内，根据加载的员工的相应激活关键词去将`input`传入不同的员工。然后是逻辑文档的解析，如果按照上文的格式去解析逻辑文档，可以将文档完全解析为一个`字典列表`，键是调用的方法，值是传入的值（字典是 字符串:列表的形式，列表内是字符串）。

​	框架运行时会将utils内的程序集加载到框架内部，通过反射去调用方法（我这里猜想的是方法都是传入一个json字符串，然后内部进行参数解析），然后输出继续进入流，本质是对解析结果的一个遍历和迭代。

## 结语

​	本文猜想了一个可能的采用ai的单应用领域泛用性程序，{% u 其泛用性主要还是依赖于通用库和通用逻辑的开发，而不是依赖于LLM。 %}也猜想了其对应的实现结构，结果是其对应的结构和对性能的需求基于当下的硬件和软件水平进行开发是可行的，但是结构值得优化。

​	以后的更新都会发表于本文本章后的“更新”章节中，包括架构的调整和需求的总结（这里给自己埋一个坑），感谢各位读者的阅读。



